# -*- coding: utf-8 -*-
"""game-recommender-system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15I1ikBktdDUxOAhq77At9aM-sriHtwoI
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import kagglehub
import gc
from datetime import datetime

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neighbors import NearestNeighbors
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
from scipy.sparse import csr_matrix
from mlxtend.frequent_patterns import apriori, association_rules

from scipy.sparse import coo_matrix

"""#DATA LOADING AND DATA UNDERSTANDING

### Fungsi mengurangi penggunaan memori
"""

def reduce_memory(df):
    for col in df.columns:
        if df[col].dtype == 'float64':
            df[col] = df[col].astype('float32')
        if df[col].dtype == 'int64':
            df[col] = df[col].astype('int32')
    return df

def data_generator(df, chunksize=10000):
    for i in range(0, df.shape[0], chunksize):
        yield df.iloc[i:i+chunksize]

"""### Fetch dataset dari Kaggle"""

# Download latest version
path = kagglehub.dataset_download("antonkozyriev/game-recommendations-on-steam")

print("Path to dataset files:", path)

# games = pd.read_csv(path + '/games.csv')
# recommendations = pd.read_csv(path + '/recommendations.csv')
# users = pd.read_csv(path + '/users.csv')
# metadatas = pd.read_json(path + '/games_metadata.json', lines=True)

games = reduce_memory(pd.read_csv(path + '/games.csv'))
recommendations = reduce_memory(pd.read_csv(path + '/recommendations.csv'))
users = reduce_memory(pd.read_csv(path + '/users.csv'))
metadatas = reduce_memory(pd.read_json(path + '/games_metadata.json', lines=True))

print(recommendations.info(memory_usage='deep'))

"""## Cek dataset

### Cek panjang data
"""

print(games.shape)
print(recommendations.shape)
print(users.shape)
print(metadatas.shape)

"""###Cek informasi tiap tabel"""

print(games.info())
print(recommendations.info())
print(users.info())
print(metadatas.info())

"""###Cek Missing Values"""

print("Users Dataset:\n", users.isnull().sum())
print("\nGames Dataset:\n", games.isnull().sum())
print("\nRecommendations Dataset:\n", recommendations.isnull().sum())
print("\nMetadatas Dataset:\n", metadatas.isnull().sum())

"""###Cek isi dataset

Convert kolom date_release ke format datetime
"""

games['date_release'] = pd.to_datetime(games['date_release'])
recommendations['date'] = pd.to_datetime(recommendations['date'])

"""Filter dataset recommendations (memakan banyak RAM)"""

recommendations_final = recommendations[
    (recommendations['hours'] > 2) &
    (recommendations['hours'] < (
        recommendations['hours'].quantile(.75) + 1.5 * (recommendations['hours'].quantile(.75) - recommendations['hours'].quantile(.25))
    ))
].copy()
recommendations_final = reduce_memory(recommendations_final)

"""Hapus dataset recommendations pra filter"""

del recommendations
gc.collect()

games

recommendations_final

users

metadatas

"""#EXPLORATORY DATA ANALYSIS (EDA)

##Analisis Games

###Distribusi game berdasarkan rating
"""

sns.countplot(data=games, x='rating', palette='crest')
plt.title('Distribusi Rating Game di STEAM')
plt.xlabel('Rating')
plt.xticks(rotation=90)
plt.ylabel('Jumlah')
plt.show()

"""###Distribusi game berdasarkan Tags"""

from collections import Counter

all_tags = metadatas['tags'].dropna().explode()
tag_counts = Counter(tag for tags in metadatas['tags'].dropna() for tag in tags)

tags_df = pd.DataFrame(tag_counts.items(), columns=['tag', 'count'])
tags_df = tags_df.sort_values('count', ascending=False)

plt.figure(figsize=(10, 5))
sns.histplot(tags_df['count'], bins=50, kde=True)
plt.title("Distribusi Frekuensi Semua Tags")
plt.xlabel("Jumlah Game dengan Tag Tertentu")
plt.ylabel("Jumlah Tag")
plt.tight_layout()
plt.show()

from collections import Counter
tag_counter = Counter(tag for tags in metadatas['tags'].dropna() for tag in tags)
top_20_tags = pd.DataFrame(tag_counter.most_common(15), columns=["Tag", "Count"])

plt.figure(figsize=(25, 10))
sns.barplot(data=top_20_tags, x="Tag", y="Count", palette="crest")
plt.xticks(rotation=90)
plt.title("Distribusi TOP 15 Tags")
plt.xlabel("Tag")
plt.ylabel("Jumlah Game")
plt.tight_layout()
plt.show()

"""###Distribusi game berdasarkan platform"""

platform_counts = games[['win', 'mac', 'linux', 'steam_deck']].sum()

plt.figure(figsize=(6, 6))
plt.pie(platform_counts, labels=platform_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Persentase Game yang Mendukung Setiap Platform')
plt.axis('equal')
plt.show()

"""###Distribusi diskon dan harga"""

sns.histplot(data=games, x='discount', bins=30)
plt.title('Distribusi Diskon Game di STEAM')

plt.figure(figsize=(15, 6))
sns.histplot(data=games[games['price_final'] < 100], x='price_final', bins=30, kde=True)
plt.title('Distribusi Harga Akhir Game')

"""###Game populer dengan review terbanyak"""

top_games = games.sort_values('user_reviews', ascending=False).head(10)
sns.barplot(data=top_games, y='title', x='user_reviews', palette='crest')
plt.title('10 Game dengan Review Terbanyak')

"""###Tren rilis game"""

plt.figure(figsize=(15, 6))
games['date_release'].dt.year.value_counts().sort_index().plot(kind='line')
plt.title('Jumlah game yang dirilis per tahun')
plt.xlabel('Tahun')
plt.ylabel('Jumlah')
plt.show()

"""##Analisis Users

###Distribusi jumlah game yang dimiliki user
"""

plt.figure(figsize=(12, 6))
sns.histplot(data=users[users['products'] < 1000], x='products', bins=30)
plt.title('Distribusi Jumlah Game per User')
plt.xlabel('Products')
plt.show()

"""###Distribusi jumlah review yg ditulis per User"""

plt.figure(figsize=(12, 6))
sns.histplot(data=users[users['reviews'] < 20], x='reviews', bins=30)
plt.title('Distribusi Jumlah Review per User')
plt.xlabel('Reviews')
plt.show()

"""##Analisis Recommends

###Dsitribusi playtime
"""

plt.figure(figsize=(12, 4))
sns.histplot(data=recommendations_final, x='hours', bins=50, kde=True, log_scale=True)
plt.title('Distribusi Waktu Bermain')
plt.xlabel('Waktu Bermain (Jam) - Skala Log')
plt.ylabel('Frekuensi')
plt.show()

plt.figure(figsize=(12, 6))
sns.boxplot(data=recommendations_final, x='hours')
plt.title('Hours played')
plt.show()

"""#DATA PREPARATION

###Merge dataset games dengan metadata untuk mendapatkan deskripsi serta tags tiap game
"""

game_final = pd.merge(
    games, metadatas, on = 'app_id', how = 'inner'
)
game_final = reduce_memory(game_final)
game_final.head()

merged_df = recommendations_final.merge(game_final[['app_id', 'title']], on='app_id', how='inner')

filtered_df = merged_df[merged_df['is_recommended'] == True]

"""Tidak memakai pivot table untuk mengurangi memory usage"""

# user_game_matrix = filtered_df.pivot_table(index='user_id', columns='title', values='hours', fill_value=0)

user_to_idx = {user_id: idx for idx, user_id in enumerate(recommendations_final['user_id'].unique())}
game_to_idx = {app_id: idx for idx, app_id in enumerate(recommendations_final['app_id'].unique())}

idx_to_user = {idx: user_id for user_id, idx in user_to_idx.items()}
idx_to_game = {idx: app_id for app_id, idx in game_to_idx.items()}

user_indices = filtered_df['user_id'].map(user_to_idx)
game_indices = filtered_df['title'].map(game_to_idx)
# hours_values = filtered_df['hours'].values

valid_mask = user_indices.notna() & game_indices.notna()

user_indices = user_indices[valid_mask].astype(int).values
game_indices = game_indices[valid_mask].astype(int).values
hours_values = filtered_df['hours'][valid_mask]

"""#MODELING

##USER BASED COLLABORATIVE FILTERING
"""

num_users_ubf = len(user_to_idx)
num_games_ubf = len(game_to_idx)
user_game_sparse_matrix_ubf = csr_matrix((hours_values, (user_indices, game_indices)), shape=(num_users_ubf, num_games_ubf))

"""Fit model KNN"""

model_knn = NearestNeighbors(metric='cosine', algorithm='brute')
model_knn.fit(user_game_sparse_matrix_ubf)

def ubf(user_id, top_n=5):
    if user_id not in user_to_idx:
        print(f"User ID {user_id} not found in the dataset for UBF.")
        return []

    user_idx = user_to_idx[user_id]
    # similar_users = user_similarity_df[user_id].sort_values(ascending=False)[1:6]

    distances, indices = model_knn.kneighbors(user_game_sparse_matrix_ubf.getrow(user_idx), n_neighbors=top_n + 1)
    similar_users_codes = indices.flatten()[1:]
    similar_users_ids = [idx_to_user[code] for code in similar_users_codes]

    # rekomendasi
    games_played_by_user = set(recommendations_final[recommendations_final['user_id'] == user_id]['app_id'].unique())

    recommendations_score = {}
    for sim_user_id in similar_users_ids:
        sim_user_recs = recommendations_final[recommendations_final['user_id'] == sim_user_id]
        for _, row in sim_user_recs.iterrows():
            app_id = row['app_id']
            hours = row['hours']
            if app_id not in games_played_by_user:
                recommendations_score[app_id] = recommendations_score.get(app_id, 0) + hours
    sorted_recs = sorted(recommendations_score.items(), key=lambda item: item[1], reverse=True)
    recommended_game_titles = []
    for app_id, _ in sorted_recs[:top_n]:
        game_info = game_final[game_final['app_id'] == app_id]
        if not game_info.empty:
            title = game_info['title'].iloc[0]
            recommended_game_titles.append(title)
        else:
            print(f"Warning: app_id {app_id} tidak ditemukan.")
    return recommended_game_titles

"""##CONTENT BASED

TF-IDF dengan Cosine similarity
"""

game_final['tags_string'] = game_final['tags'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')
game_final['combined_features'] = game_final['title'].fillna('') + ' ' + game_final['tags_string']

print(filtered_df.info())
print(game_final.info())

tfidf = TfidfVectorizer(stop_words='english', analyzer='word', ngram_range=(1, 2), min_df=5)
tfidf_matrix = tfidf.fit_transform(game_final['combined_features'])

title_to_index = pd.Series(game_final.index, index=game_final['title'])

def cbf(game_title, top_n=5):
    if game_title not in title_to_index:
        print(f"Game '{game_title}' tidak ditemukan.")
        return []
    idx = title_to_index[game_title]
    cosine_similarities = linear_kernel(tfidf_matrix[idx], tfidf_matrix).flatten()
    similar_indices = cosine_similarities.argsort()[-top_n-1:-1][::-1]
    return game_final.iloc[similar_indices]['title']

"""##HYBRID"""

def hybrid(user_id, top_n=5):
    user_based_titles = ubf(user_id, top_n=20)
    user_based_app_ids = []
    for title in user_based_titles:
        game_info = game_final[game_final['title'] == title]
        if not game_info.empty:
            user_based_app_ids.append(game_info['app_id'].iloc[0])
    user_based_app_ids = list(set(user_based_app_ids))

    games_played_by_target_user = set(recommendations_final[recommendations_final['user_id'] == user_id]['app_id'].unique())

    hybrid_scores = {}
    for app_id in user_based_app_ids:
        game_info_in_final = game_final[game_final['app_id'] == app_id]
        if not game_info_in_final.empty:
            game_idx_in_final = game_info_in_final.index[0]
            cosine_sims = linear_kernel(tfidf_matrix[game_idx_in_final], tfidf_matrix).flatten()
            for i, score in enumerate(cosine_sims):
                current_game_app_id = game_final.iloc[i]['app_id']
                if current_game_app_id not in games_played_by_target_user:
                    hybrid_scores[current_game_app_id] = hybrid_scores.get(current_game_app_id, 0) + score
    sorted_hybrid = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)

    recommended_titles = []
    for app_id, _ in sorted_hybrid:
        game_info = game_final[game_final['app_id'] == app_id]
        if not game_info.empty:
            title = game_info['title'].iloc[0]
            recommended_titles.append(title)
        if len(recommended_titles) == top_n:
            break

    return recommended_titles

"""#TES"""

recommendations_final

print("📘 User-Based:", ubf(51580))
print("📗 Content-Based:", cbf("Dota 2"))
print("📙 Hybrid:", hybrid(51580))

"""#VISUALISASI AKHIR

Chart skor kemiripan game
"""

def plot_recommendations(title, top_n=5):
    idx = title_to_index[title]
    cosine_similarities = linear_kernel(tfidf_matrix[idx], tfidf_matrix).flatten()
    similar_indices = cosine_similarities.argsort()[-top_n-1:-1][::-1]
    similar_scores = cosine_similarities[similar_indices]
    similar_titles = game_final.iloc[similar_indices]['title'].values
    plt.figure(figsize=(9, 5))
    sns.barplot(x=similar_titles, y=similar_scores, palette='crest')
    plt.xlabel('Cosine Similarity Score')
    plt.ylabel('Rekomendasi game')
    plt.xticks(rotation=45)
    plt.title(f"Top {top_n} Rekomendasi untuk '{title}'")
    plt.tight_layout()
    plt.show()

plot_recommendations("Dota 2", top_n=5)

"""Distribusi skor kemiripan"""

def plot_similarity_distribution(title):
    idx = title_to_index[title]
    cosine_similarities = linear_kernel(tfidf_matrix[idx], tfidf_matrix).flatten()

    plt.figure(figsize=(8, 5))
    sns.histplot(cosine_similarities, bins=50, kde=True, color='skyblue')
    plt.title(f'Distribution of Cosine Similarity Scores for "{title}"')
    plt.xlabel('Cosine Similarity')
    plt.ylabel('Frequency')
    plt.grid(True)
    plt.tight_layout()
    plt.show()
plot_similarity_distribution("Dota 2")

"""Hasil rekomendasi"""

def get_recommendation_df(title, top_n=5):
    idx = title_to_index[title]
    cosine_similarities = linear_kernel(tfidf_matrix[idx], tfidf_matrix).flatten()
    similar_indices = cosine_similarities.argsort()[-top_n-1:-1][::-1]

    result_df = game_final.iloc[similar_indices][['title', 'tags_string']].copy()
    result_df['similarity_score'] = cosine_similarities[similar_indices]
    return result_df

get_recommendation_df("Dota 2", top_n=5)